{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6EwGZUbyXbPr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# create english words\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IKFjxmRcXrA2"
   },
   "outputs": [],
   "source": [
    "# os.listdir('drive/MyDrive')\n",
    "# read the data\n",
    "data = pd.read_csv('drive/MyDrive/dataset.csv' , encoding = \"ISO-8859-1\" , engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVI1ksJYX7yp",
    "outputId": "87692495-5ac2-4287-b68b-d4bde3a8645b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154169, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "eoOvgEV5Y3Hd",
    "outputId": "a6bd8810-5a46-48af-c0fa-19b84a2d626f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>TextBody</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>???: My flight Nov 11/17 AA125 DFW-HKG</td>\n",
       "      <td>Hi,\\n\\nI haven't received your reply yet, can ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re: ??: My flight Nov 11/17 AA125 DFW-HKG    [...</td>\n",
       "      <td>Pls cancel it for me and I will use it later. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RE: Tuesday, 05Feb, 2019: Ticketed itinerary f...</td>\n",
       "      <td>I could not book my hotel because you all did ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RE: Tuesday, 05Feb, 2019: Ticketed itinerary f...</td>\n",
       "      <td>Hi Renee,\\nI ended up booking the hotel on Exp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RE: Tuesday, 05Feb, 2019: Ticketed itinerary f...</td>\n",
       "      <td>Wow!  Thanks for the great customer service an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  ... Unnamed: 4\n",
       "0          ???: My flight Nov 11/17 AA125 DFW-HKG  ...        NaN\n",
       "1  Re: ??: My flight Nov 11/17 AA125 DFW-HKG    [...  ...        NaN\n",
       "2  RE: Tuesday, 05Feb, 2019: Ticketed itinerary f...  ...        NaN\n",
       "3  RE: Tuesday, 05Feb, 2019: Ticketed itinerary f...  ...        NaN\n",
       "4  RE: Tuesday, 05Feb, 2019: Ticketed itinerary f...  ...        NaN\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# few samples\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5Oqy2DEPWB4",
    "outputId": "54e16823-3812-4f72-b37c-a9b434a61367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject        79101\n",
       "TextBody       79132\n",
       "Unnamed: 2    154168\n",
       "Unnamed: 3    154168\n",
       "Unnamed: 4    154168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nulls\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QB_VXfQzQiyi"
   },
   "outputs": [],
   "source": [
    "# drop row wise null vales\n",
    "data1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S2o0CY8_coAz"
   },
   "outputs": [],
   "source": [
    "data = data[['Subject' , \"TextBody\"]].dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPhl9Gn2dhHz",
    "outputId": "7239cf6c-0dd3-486b-d96b-df1eb2c4ed87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject     0\n",
       "TextBody    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "y9MIWDtnY5JQ",
    "outputId": "84d32821-04ff-4c2d-baa1-b41e37fdcfac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hi,\\n\\nI haven't received your reply yet, can you check and let me know? The case # is 00870466.\\n\\nThank you!\\n\\n________________________________\\nYihua Huang (Summer), Sales Manager\\nDUNAN PRECISION INC.\\nCell (USA): +1-214-909-7983\\nCell (China): +86-138-2557-4218\\nEmail (USA): summer.huang@dunanusa.com\\nEmail (China): summer@dunan.cn\\nURL (USA): www.dunanusa.com\\nURL (China): www.dunan.net\\nAddress: 12840 Hillcrest Road #E230, Dallas, TX 75230\\n\\n\\x86\\x8f?\\x84¯?\\x84§§\\x8b¬? Summer Huang \\x82¯?\\x91§\\x9b\\x86\\x8d?<mailto:summer.huang@dunanUSA.com>\\n\\x86\\x8f?\\x82?\\x81\\x91??\\x82??\\x8b¬? 2018-10-26 09:57\\n\\x91??\\x84¯?\\x84§§\\x8b¬? travelsupport<mailto:travelsupport@ganttravel.com>\\n\\x84?¯\\x82\\x9b?\\x8b¬? My flight Nov 11/17 AA125 DFW-HKG\\nHi,\\n\\nCan you check the remaining value of the ticket if I cancel my flight on Nov 11/17 AA125 DFW-HKG (Confirmation: DPYFKF)?\\n\\nThank you!\\n\\n________________________________\\nYihua Huang (Summer), Sales Manager\\nDUNAN PRECISION INC.\\nCell (USA): +1-214-909-7983\\nCell (China): +86-138-2557-4218\\nEmail (USA): summer.huang@dunanusa.com\\nEmail (China): summer@dunan.cn\\nURL (USA): www.dunanusa.com\\nURL (China): www.dunan.net\\nAddress: 12840 Hillcrest Road #E230, Dallas, TX 75230\""
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample text body\n",
    "data.iloc[0]['TextBody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JheuJf8ZZEsN",
    "outputId": "aaa4d3e1-8126-42e1-eeff-0c739df92f5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['summer.huang@dunanusa.com',\n",
       "  'summer@dunan.cn',\n",
       "  'summer.huang@dunanUSA.com',\n",
       "  'travelsupport@ganttravel.com',\n",
       "  'summer.huang@dunanusa.com',\n",
       "  'summer@dunan.cn']]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function tries to extract email from a text\n",
    "def getEmail(text):\n",
    "  emails =  []\n",
    "  pattern = r'[\\w\\.]+@[\\w\\.]+\\.[\\w]+'\n",
    "  #further cleaning will be done to remove duplicates\n",
    "  emails.append(re.findall(pattern , data.iloc[0]['TextBody']))\n",
    "  return emails\n",
    "\n",
    "# test with head\n",
    "getEmail(data.head(45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XAQLnTD4Zhii"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JppiZhnnao8o"
   },
   "outputs": [],
   "source": [
    "# take a sample of data to use for cleaning\n",
    "# df = data.sample(30 , random_state=42)\n",
    "# This will help us while we are trying to clean the data\n",
    "df = data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdg_Xq8olMKl",
    "outputId": "1328ae99-4031-4735-ddc0-0ae7abf5f4d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74938, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "V5mfdhlStNEC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XpnSDp1Stdqe"
   },
   "outputs": [],
   "source": [
    "# pattern to match phones numbers\n",
    "phone_pattern = r'\\d*\\s\\d+\\s\\d+\\s\\d+'\n",
    "#pattern to match any email  in a text\n",
    "email_pattern = r'[\\w\\.]+@[\\w\\.]+\\.[\\w]+'\n",
    "#this is for matching urls..\n",
    "# i scrambled trying it out.. i had to write the long one to match every type of url\n",
    "url_pattern = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "\n",
    "import string\n",
    "writable = set(string.printable)\n",
    "\n",
    "# all functions takes text which is the sentiment  to be processed\n",
    "# the all also return the processed text\n",
    "def removeNonAsciiChars(text):\n",
    "  \"\"\"\n",
    "  This function removes any non characters in english  like the hex encodings e.g \\x86\\x8d etc\n",
    "  \"\"\"\n",
    "  return ''.join(filter(lambda x: x in writable, text))\n",
    "\n",
    "\n",
    "\n",
    "def GetEnglishWords(text):\n",
    "  \"\"\"This function is used to get all English words found in NLTK CORPUS\"\"\"\n",
    "  sent = text\n",
    "  text = \" \".join(w for w in nltk.wordpunct_tokenize(sent) if w.lower() in words or not w.isalpha())\n",
    "  return text\n",
    "\n",
    "def remove_keywords(text):\n",
    "  \"\"\"Returns a text which have removed the following keywords used in emails\"\"\"\n",
    "  text = text.replace(\"Subject\" , \"\")\n",
    "  text = text.replace(\"Subject\" , \"\")\n",
    "  text = text.replace(\"Re:\" , \"\")\n",
    "  text = text.replace(\"Subject\" , \"\")\n",
    "  return text\n",
    "\n",
    "\n",
    "# this is the main function that does cleaning\n",
    "def text_cleaning(text):\n",
    "    \"\"\"\n",
    "    I decided to subsitute all # signs with Number\n",
    "    I sliced part of text from where emails are starting...Like after a messages the Emails replied to\n",
    "    I removed all emails found in the text\n",
    "    I removed all urls found in the text\n",
    "    Removed more than two spaces or undescores\n",
    "    \"\"\"\n",
    "    #subsitute # with number\n",
    "    text = re.sub(\"#\" , \"Number \"  , text)\n",
    "    \n",
    "\n",
    "    #slice the text to where emails are starting\n",
    "    email_match = re.findall(email_pattern , text)\n",
    "    if len(email_match)>0:\n",
    "      text = text.partition(email_match[0])[0]\n",
    "\n",
    "    #slice the text until it find \"Sent From\"  text if doesnt found it return text\n",
    "    sender_end = re.findall(\"Sent from\" , text)\n",
    "    if len(sender_end)>0:\n",
    "      text = text.partition(sender_end[0])[0]\n",
    "\n",
    "    #remove emails from the text\n",
    "    text = re.sub(email_pattern , \"\" , text)\n",
    "    #remove urls\n",
    "    #remove any urls found in the text\n",
    "    text = re.sub(url_pattern , \"\" ,  text)\n",
    "    #remove more than two spaces\n",
    "    text = re.sub(\"\\s\\s*\" , \" \" , text)\n",
    "    #remove underscore with this pattern \n",
    "    text = re.sub('________________________________' , \"\" , text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# remove phone number\n",
    "def removePhone(text):\n",
    "  \"\"\"Removes phone numbers from the text , This is from the most common patter found in text\"\"\"\n",
    "  return re.sub(phone_pattern , \"\" , text)\n",
    "\n",
    "\n",
    "# get to remove some puctuations\n",
    "def getRidPunct(text):\n",
    "  \"\"\"\n",
    "  Removes some punctions predefined below\n",
    "  I predefined some punctuations since some are import in the email\n",
    "  \"\"\"\n",
    "  punctuations = '''()-[]{};:'\"\\,<>./?@#$%§+^&*_~'''\n",
    "  # define a var to hold all no punctuated\n",
    "  no_punct = \"\"\n",
    "  for char in text:\n",
    "    if char not in punctuations:\n",
    "        no_punct = no_punct + char\n",
    "\n",
    "  return no_punct\n",
    "\n",
    "# get the most  important text\n",
    "def partText(text):\n",
    "  \"\"\"\n",
    "  In this function I defined some regex that are used to extract some part of the word\n",
    "  In this regex , I identified that after an email , It is followed by more that 4 words\n",
    "  which starts with upper case  so the pattern is [A-Z]\\w+\\s* and it repearts 4 or 5 times followed by a digit\n",
    "  \"\"\"\n",
    "  caps_matcher = r\"\\s+[A-Z]\\w+\\s* [A-Z]\\w+\\s* [A-Z]\\w+\\s* [A-Z]\\w+\\s* [A-Z]\\w+\\s* [\\d]\\w+\\s*\"\n",
    "  matching = re.findall(caps_matcher , text)\n",
    "  # if there is matching of the above regex i return the first one else i return the original text\n",
    "  if len(matching)>0:\n",
    "    return text.partition(matching[0])[0] + \" \" + \"\".join(matching).split()[1]\n",
    "  else:\n",
    "    return text\n",
    "\n",
    "\n",
    "def correctWords(text):\n",
    "  \"\"\"Using Textblob library , To correct spellings of the english words found\"\"\"\n",
    "  import textblob\n",
    "  text = textblob.TextBlob(text).correct()    \n",
    "  return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JRBtS9uzkyZG"
   },
   "outputs": [],
   "source": [
    "# # \n",
    "def mainCaller(text):  \n",
    "  \"\"\"\n",
    "  This is the main Function for the program\n",
    "  You just need to call it using apply method to a series\n",
    "  e.g  Series.apply(function_name)\n",
    "  If you are calling it with a string just call it normally like function_name(text = string)\n",
    "  The function returns a string.\n",
    "  \"\"\"\n",
    "  text = removeNonAsciiChars(text)\n",
    "  text = remove_keywords(text)\n",
    "  text = text_cleaning(text)\n",
    "  text = getRidPunct(text)\n",
    "  text = removePhone(text)\n",
    "  text = partText(text)\n",
    "  text = GetEnglishWords(text)\n",
    "  text = correctWords(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qtWMLQV6ph_H"
   },
   "outputs": [],
   "source": [
    "# this is for the sample that we created. for the test\n",
    "df['cleaned'] = df['TextBody'].apply(mainCaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcv46YMJ8C1X",
    "outputId": "66ab5b37-630e-4146-902e-d904a5a0396b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I haven received your reply yet can you check and let me know The case Number is 00870466 Thank you ! Summer Manager PRECISION\n",
      "\n",
      "\n",
      "\n",
      "cancel it for me and I will use it later Thanks ! Outlook for Travel Support\n",
      "\n",
      "\n",
      "\n",
      "I could not book my hotel because you all did not have it Western Premier I stayed there 2 ago your its not listed Please call me to discuss Rank Rank\n",
      "\n",
      "\n",
      "\n",
      "I I ended up booking the hotel on I stay at this hotel all the selected it on my previous trip in Concur I spent over 30 trying to find it on your system last night before giving up Please escapade the have someone tell me what Key or I should use in the future so as not to have this issue I in All as the area tried all for West Western Used key West Western Premier in the hotel actual address And still nothing came up for Premier on Rank\n",
      "\n",
      "\n",
      "\n",
      "Now ! Thanks for the great customer service and more importantly now I know its not me going insane ! ! I use this hotel somehow got it on concur for my previous again for the quick reaction ! Sincerely Rank From Travel Support\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in df['cleaned'].head():\n",
    "  print(each)\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fpfTC0RO7xlp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXk9JbikqdXW"
   },
   "outputs": [],
   "source": [
    "# create a new columns to store our cleaned text\n",
    "data['cleaned'] = data['TextBody'].apply(mainCaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1NNrVckwIQGE"
   },
   "outputs": [],
   "source": [
    "# NOTE -- This cell was used for testing ... \n",
    "# I have created an function that does that automatically\n",
    "\n",
    "\n",
    "# df['cleaned'] = \"\"\n",
    "# for row in range(df.shape[0]):\n",
    "#   # text = \"\"\n",
    "#   checker =  df.iloc[row]['TextBody']\n",
    "#   text = checker\n",
    "#   # # find this words \n",
    "#   # if \"Thanks\" in checker:\n",
    "#   #   text = checker.partition('Thanks')[0]+\" Thanks\"\n",
    "\n",
    "#   # if \"From\" in checker:\n",
    "#   #   text = checker.partition('From')[0]\n",
    "#   # # if \"Sincerely\" in checker\n",
    "#   # else:\n",
    "#   #   text = checker.partition('\\n\\n\\n')[0]\n",
    "\n",
    "#   text = removeNonAsciiChars(text)\n",
    "#   text = remove_keywords(text)\n",
    "#   text = text_cleaning(text)\n",
    "#   text = getRidPunct(text)\n",
    "#   text = removePhone(text)\n",
    "#   text = partText(text)\n",
    "\n",
    "#   df.loc[row]['cleaned'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rZwx5Z0ep-3F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EmailPrepro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
